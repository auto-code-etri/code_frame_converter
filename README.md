CodeFrameConverter

ğŸ“Œ Project Overview

This project is a pipeline designed to \*\*automatically collect, refine, and convert crawled code data into high-quality datasets for LLM training\*\*.  

It follows the process of \*\*Code Crawling â†’ DataFrame Conversion â†’ Filtering \& Scoring â†’ Natural Language Conversion\*\*, with the goal of generating clean and useful parallel datasets of code and text.

---

ğŸš€ Key Features

1. Code Crawling (step0\_crawling.ipynb)  
  - Collect code from web/repositories and save it in JSON format

2. DataFrame Conversion (step1\_json\_to\_df.ipynb)
 - Convert JSON into Pandas DataFrame to organize and inspect data

3. Data Filtering (step2\_filtering.ipynb)  
 - Remove unnecessary or low-quality code  
 - Apply rule-based and condition-based filtering  

4. Scoring (step3\_scoring.ipynb)
 - Evaluate code quality and usefulness  
 - Assign scores to individual samples within the dataset  

5. Natural Language Conversion (step4\_converting.ipynb)
 - Generate natural language descriptions for code  
 - Build a parallel dataset of \*\*codeâ€“text pairs\*\*  

---

ğŸ“‚ Folder Structure

root/

â”œâ”€ code\_converted/ # Final dataset with natural language conversion

â”œâ”€ code\_filtered/ # Filtered code dataset

â”œâ”€ code\_source/ # Source code dataset converted to JSON

â”œâ”€ crawled\_source/ # Crawled raw source code files (starting point)

â”‚â”€â”€ step0(crawling).ipynb # Code crawling

â”‚â”€â”€ step1(json\_to\_df).ipynb # JSON â†’ DataFrame

â”‚â”€â”€ step2(filtering).ipynb # Code filtering

â”‚â”€â”€ step3(scoring).ipynb # Code scoring

â”‚â”€â”€ step4(converting).ipynb # Code-to-natural-language conversion

â”‚â”€â”€ README.md


âš™ï¸ Installation
pip install -r requirements.txt

âš™ï¸ Output
High-quality codeâ€“natural language paired dataset for LLM training (in code\_converted folder)

